{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f8d4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1937d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/processed/combined_labeled_standardized.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "# df =df.dropna(axis='columns')\n",
    "df = df.dropna(axis=1)  # Drop columns with all NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57259e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a856f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['patient_id', 'healthy'], axis=1)\n",
    "y = df['healthy']\n",
    "# Create train, validation, and test sets\n",
    "# First split into temp training (80%) and test (20%)\n",
    "X_train_full, X_val, y_train_full, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f04e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Step 1: Split into train, validation, and test\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "X_train\n",
    "\n",
    "components = 20\n",
    "# Create a pipeline with PCA and various classifiers\n",
    "models = {\n",
    "    'Decision Tree': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca', PCA(n_components=components)),\n",
    "        ('classifier', DecisionTreeClassifier())\n",
    "    ]),\n",
    "    'Random Forest': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca', PCA(n_components=components)),\n",
    "        ('classifier', RandomForestClassifier())    \n",
    "    ]),\n",
    "    'SVM': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca', PCA(n_components=components)),\n",
    "        ('classifier', SVC(probability=True))\n",
    "    ]),\n",
    "    'KNN': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca', PCA(n_components=components)),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ]),\n",
    "    'Gradient Boosting': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca', PCA(n_components=components)),\n",
    "        ('classifier', GradientBoostingClassifier())\n",
    "    ]),\n",
    "    'Neural Network': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca', PCA(n_components=components)),\n",
    "        ('classifier', MLPClassifier(max_iter=1000))\n",
    "    ])\n",
    "}\n",
    "results = {}\n",
    "model_names = list(models.keys())\n",
    "accuracies = []\n",
    "std_devs = []\n",
    "validation_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for name, pipeline in models.items():\n",
    "# Step 3: Cross-validation on training set\n",
    "    cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    print(\"Cross-validation scores:\", cv_scores)\n",
    "    print(\"Mean CV accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "    # Step 4: Fit on training data and evaluate on validation\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    val_preds = pipeline.predict(X_val)\n",
    "    print(\"Validation Accuracy:\", accuracy_score(y_val, val_preds))\n",
    "    print(\"Validation Classification Report:\\n\", classification_report(y_val, val_preds))\n",
    "\n",
    "    # Step 5: Final test evaluation (optional, only after tuning)\n",
    "    test_preds = pipeline.predict(X_test)\n",
    "    print(\"Test Accuracy:\", accuracy_score(y_test, test_preds))\n",
    "    print(\"Test Classification Report:\\n\", classification_report(y_test, test_preds))\n",
    "    mean_accuracy = cv_scores.mean()\n",
    "    std_accuracy = cv_scores.std()\n",
    "    val_accuracy = accuracy_score(y_val, val_preds)\n",
    "    \n",
    "    results[name] = {\n",
    "            'mean_accuracy': mean_accuracy,\n",
    "            'std_accuracy': std_accuracy,\n",
    "            'validation_accuracy': val_accuracy,\n",
    "        }\n",
    "    \n",
    "    # Store in lists for plotting\n",
    "    accuracies.append(mean_accuracy)\n",
    "    std_devs.append(std_accuracy)\n",
    "    validation_accuracies.append(val_accuracy)\n",
    "    # Create a DataFrame to summarize results\n",
    "    \n",
    " # Create a comparison plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create bar chart with cross-validation accuracy\n",
    "bars = plt.bar(model_names, accuracies, yerr=std_devs, capsize=10, alpha=0.7, color='skyblue', label='Cross-validation Accuracy')\n",
    "\n",
    "# Add validation accuracy as a separate point\n",
    "plt.plot(model_names, validation_accuracies, 'ro', markersize=8, label='Validation Accuracy')\n",
    "\n",
    "# Add test accuracy as another point\n",
    "# plt.plot(model_names, test_accuracies, 'go', markersize=8, label='Test Accuracy')\n",
    "\n",
    "# Add text labels for cross-validation accuracy\n",
    "for i, (bar, acc) in enumerate(zip(bars, accuracies)):\n",
    "    plt.text(i, acc/2, f'{acc:.2f}', ha='center', va='center', color='white', fontweight='bold')\n",
    "\n",
    "# Add text labels for validation and test accuracy\n",
    "for i, v in enumerate(validation_accuracies):\n",
    "    plt.text(i, v + 0.03, f'{v:.2f}', ha='center', fontsize=10, color='red')\n",
    "# for i, t in enumerate(test_accuracies):\n",
    "#     plt.text(i, t - 0.03, f'{t:.2f}', ha='center', fontsize=10, color='green')\n",
    "\n",
    "plt.title(f'Model Comparison with PCA ({components} components)', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.xlabel('Models', fontsize=12)\n",
    "plt.ylim(0, 1.1)  # Adjusted to fit the text labels\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a dataframe from the results\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': model_names,\n",
    "    'Cross-validation Accuracy': accuracies,\n",
    "    'Validation Accuracy': validation_accuracies\n",
    "})\n",
    "\n",
    "# Create a figure with a decent size\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Set width of bars\n",
    "bar_width = 0.35\n",
    "index = range(len(model_names))\n",
    "\n",
    "# Create the bars\n",
    "plt.bar([i - bar_width/2 for i in index], results_df['Cross-validation Accuracy'], \n",
    "        width=bar_width, label='CV Accuracy', color='skyblue', alpha=0.8)\n",
    "plt.bar([i + bar_width/2 for i in index], results_df['Validation Accuracy'], \n",
    "        width=bar_width, label='Validation Accuracy', color='lightcoral', alpha=0.8)\n",
    "\n",
    "# Add value labels on the bars\n",
    "for i, v in enumerate(results_df['Cross-validation Accuracy']):\n",
    "    plt.text(i - bar_width/2, v + 0.02, f'{v:.2f}', ha='center', fontsize=10)\n",
    "    \n",
    "for i, v in enumerate(results_df['Validation Accuracy']):\n",
    "    plt.text(i + bar_width/2, v + 0.02, f'{v:.2f}', ha='center', fontsize=10)\n",
    "\n",
    "# Add labels, title and legend\n",
    "plt.xlabel('Models', fontsize=12)\n",
    "plt.ylabel('Accuracy Score', fontsize=12)\n",
    "plt.title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "plt.xticks(index, model_names, rotation=45, ha='right')\n",
    "plt.ylim(0.8, 1.1)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c4e20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Calculate F1 scores for each model\n",
    "f1_scores = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Get model predictions on validation set\n",
    "    val_predictions = model.predict(X_val)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(y_val, val_predictions, average='binary')\n",
    "    f1_scores.append(f1)\n",
    "    print(f\"{name} - F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Create a figure with a decent size\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Set width of bars\n",
    "bar_width = 0.25\n",
    "index = np.arange(len(model_names))\n",
    "\n",
    "# Create the bars for CV Accuracy, Validation Accuracy, and F1 Score\n",
    "plt.bar(index - bar_width / 2, accuracies, width=bar_width, label='CV Accuracy', color='skyblue', alpha=0.8)\n",
    "plt.bar(index + bar_width / 2, f1_scores, width=bar_width, label='F1 Score', color='lightgreen', alpha=0.8)\n",
    "\n",
    "# Add value labels on the bars\n",
    "for i, v in enumerate(accuracies):\n",
    "    plt.text(i - bar_width / 2, v + 0.02, f'{v:.2f}', ha='center', fontsize=9)\n",
    "    \n",
    "for i, v in enumerate(f1_scores):\n",
    "    plt.text(i + bar_width / 2, v + 0.02, f'{v:.2f}', ha='center', fontsize=9)\n",
    "\n",
    "# Add labels, title and legend\n",
    "plt.xlabel('Models', fontsize=12)\n",
    "plt.ylabel('Score', fontsize=12)\n",
    "plt.title('Model Performance Comparison - F1 Score', fontsize=14, fontweight='bold')\n",
    "plt.xticks(index, model_names, rotation=45, ha='right')\n",
    "plt.ylim(0, 1.1)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db0bb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pca = PCA(n_components=1).fit(X)\n",
    "\n",
    "# Get the PCA components (loadings)\n",
    "components = pca.components_\n",
    "\n",
    "# Create a DataFrame of feature importances\n",
    "component_df = pd.DataFrame()\n",
    "component_df['Feature'] = X.columns\n",
    "component_df['Weight'] = np.abs(components[0])  # Take absolute values for importance\n",
    "\n",
    "# Sort by absolute weight\n",
    "component_df = component_df.sort_values('Weight', ascending=False)\n",
    "\n",
    "# Display top features\n",
    "top_n = 20  # Number of top features to display\n",
    "print(f\"Top {top_n} features contributing to the first PCA component:\")\n",
    "print(component_df.head(top_n))\n",
    "\n",
    "# Plot top features\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(component_df['Feature'].head(top_n)[::-1], component_df['Weight'].head(top_n)[::-1])\n",
    "plt.xlabel('Absolute Weight in First Principal Component')\n",
    "plt.title(f'Top {top_n} Features in PCA')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Get the top 20 features from the component dataframe\n",
    "top_features = component_df.head(top_n)['Feature'].values\n",
    "\n",
    "# Create a dataframe with just these top features\n",
    "top_features_df = df[np.append(top_features, 'healthy')]\n",
    "\n",
    "# Calculate mean values for each group\n",
    "healthy_means = top_features_df[top_features_df['healthy'] == 1][top_features].mean()\n",
    "unhealthy_means = top_features_df[top_features_df['healthy'] == 0][top_features].mean()\n",
    "\n",
    "# Create a comparison dataframe\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Feature': top_features,\n",
    "    'Healthy': healthy_means.values,\n",
    "    'Non-Healthy': unhealthy_means.values\n",
    "})\n",
    "\n",
    "# Melt the dataframe for easier plotting with seaborn\n",
    "melted_df = pd.melt(comparison_df, id_vars=['Feature'], var_name='Group', value_name='Mean Expression')\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.barplot(x='Mean Expression', y='Feature', hue='Group', data=melted_df)\n",
    "plt.title('Mean Expression of Top 20 Features by Health Status', fontsize=14)\n",
    "plt.xlabel('Mean Expression Value', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.legend(title='Group')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
