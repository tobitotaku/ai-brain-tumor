{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1ee3ffb",
   "metadata": {},
   "source": [
    "# Modeling: GBM & Healthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a04a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a69e47e",
   "metadata": {},
   "source": [
    "Import preprocessed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680b6826",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_filepath = \"data/processed/metadata_gbm_healthy.csv\"\n",
    "expression_filepath = \"data/processed/expression_gbm_healthy.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2157d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_expression_df = pd.read_csv(expression_filepath, index_col='sample_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9b01de",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_csv(\n",
    "    metadata_filepath, \n",
    "    index_col='sample_id'\n",
    ")\n",
    "metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4d61c8",
   "metadata": {},
   "source": [
    "## Explorative Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80098d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = gene_expression_df\n",
    "y = metadata_df\n",
    "\n",
    "print(f\"Loaded X (features) with shape: {X.shape}\")\n",
    "print(f\"Loaded y (labels) with shape: {y.shape}\")\n",
    "\n",
    "# We already scaled the data, so we can run PCA directly\n",
    "pca = PCA(n_components=2)\n",
    "data_pca = pca.fit_transform(X)\n",
    "\n",
    "# Get the variance explained by each component\n",
    "variance_explained = pca.explained_variance_ratio_\n",
    "pc1_var = variance_explained[0] * 100\n",
    "pc2_var = variance_explained[1] * 100\n",
    "\n",
    "print(\"PCA complete.\")\n",
    "\n",
    "# Put the PCA results into a DataFrame\n",
    "pca_df = pd.DataFrame(\n",
    "    data_pca,\n",
    "    columns=['PC1', 'PC2'],\n",
    "    index=X.index\n",
    ")\n",
    "\n",
    "# Add the 1, 2, 3 labels from our 'y' file\n",
    "pca_df['label_id'] = y['label']\n",
    "\n",
    "# Create a meaningful text label for plotting\n",
    "text_label_map = {1: 'Healthy', 3: 'GBM'}\n",
    "pca_df['Diagnosis'] = pca_df['label_id'].map(text_label_map)\n",
    "\n",
    "# Infer the batch from the sample_id (TCGA or GTEX)\n",
    "pca_df['Batch (Study)'] = ['TCGA' if 'TCGA' in idx else 'GTEX' for idx in pca_df.index]\n",
    "\n",
    "print(\"PCA results merged with labels. Ready to plot.\")\n",
    "display(pca_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1170eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "sns.scatterplot(\n",
    "    data=pca_df,\n",
    "    x='PC1',\n",
    "    y='PC2',\n",
    "    hue='Diagnosis',\n",
    "    palette={'Healthy': '#457B9D', 'GBM': '#E63946'},\n",
    "    alpha=0.7,\n",
    "\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.title('PCA - Binary Classification: Healthy vs GBM', fontsize=15),\n",
    "plt.xlabel(f'PC1 ({pc1_var:.1f}% variance)', fontsize=12)\n",
    "plt.ylabel(f'PC2 ({pc2_var:.1f}% variance)', fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d820f3e",
   "metadata": {},
   "source": [
    "### Top 30 most impactful genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4246f726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# We need y as a 1D array for the test\n",
    "y_ravel = y.values.ravel()\n",
    "\n",
    "print(f\"Loaded X ({X.shape}) and y ({y_ravel.shape})\")\n",
    "\n",
    "gene_variances = X.var(axis=0)\n",
    "\n",
    "# We will only keep genes with a variance > 0.01\n",
    "# This is a safe threshold to remove \"dead\" genes (which have 0 variance)\n",
    "# and \"noisy\" genes (which have near-0 variance)\n",
    "variance_filter = gene_variances > 0.01 \n",
    "\n",
    "X_active_genes = X.loc[:, variance_filter]\n",
    "\n",
    "genes_removed = X.shape[1] - X_active_genes.shape[1]\n",
    "print(f\"Removed {genes_removed} constant or low-variance genes.\")\n",
    "print(f\"Running test on remaining {X_active_genes.shape[1]} active genes.\")\n",
    "\n",
    "f_scores, p_values = f_classif(X_active_genes, y_ravel)\n",
    "print(\"ANOVA F-test complete.\")\n",
    "\n",
    "gene_impact_df = pd.DataFrame({\n",
    "    'gene_id': X_active_genes.columns,\n",
    "    'f_score': f_scores,\n",
    "    'p_value': p_values\n",
    "})\n",
    "\n",
    "gene_impact_df = gene_impact_df.dropna()\n",
    "\n",
    "# Sort by the F-score (highest first)\n",
    "top_30_genes = gene_impact_df.sort_values(by='f_score', ascending=False).head(30)\n",
    "\n",
    "print(\"\\n--- Top 30 Most Impactful Genes (Corrected) ---\")\n",
    "display(top_30_genes)\n",
    "\n",
    "plt.figure(figsize=(10, 12))\n",
    "sns.barplot(\n",
    "    x='f_score',\n",
    "    y='gene_id',\n",
    "    data=top_30_genes,\n",
    "    palette='viridis',\n",
    "    hue='gene_id',\n",
    "    legend=False\n",
    ")\n",
    "plt.title('Top 30 Most Impactful Genes (ANOVA F-score)', fontsize=16)\n",
    "plt.xlabel('Impact Score (F-score)', fontsize=12)\n",
    "plt.ylabel('Gene ID', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd48d94e",
   "metadata": {},
   "source": [
    "#### Plot top gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484a7a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "top_gene_id = top_30_genes.iloc[0]['gene_id']\n",
    "\n",
    "print(f\"Plotting expression for top gene: {top_gene_id}\")\n",
    "\n",
    "plot_df = pd.DataFrame(X[top_gene_id])\n",
    "plot_df['label'] = y['label']\n",
    "text_label_map = {1: 'Healthy', 3: 'GBM'}\n",
    "plot_df['Diagnosis'] = plot_df['label'].map(text_label_map)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "sns.boxplot(\n",
    "    data=plot_df,\n",
    "    x='Diagnosis',\n",
    "    y=top_gene_id,\n",
    "    palette={'Healthy': '#457B9D', 'GBM': '#E63946'},\n",
    "    order=['Healthy', 'GBM'], \n",
    "    hue='Diagnosis', \n",
    "    legend=False     \n",
    ")\n",
    "\n",
    "sns.stripplot(\n",
    "    data=plot_df,\n",
    "    x='Diagnosis',\n",
    "    y=top_gene_id,\n",
    "    color='black',\n",
    "    alpha=0.2, \n",
    "    jitter=0.2, \n",
    "    order=['Healthy', 'GBM']\n",
    ")\n",
    "\n",
    "plt.title(f'Expression of Top Gene: {top_gene_id}', fontsize=16)\n",
    "plt.xlabel('Diagnosis', fontsize=12)\n",
    "plt.ylabel('Scaled Gene Expression', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf3cc5f",
   "metadata": {},
   "source": [
    "## Data Driven feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2a1e64",
   "metadata": {},
   "source": [
    "### LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c697504",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "y_train_ravel = y_train.values.ravel()\n",
    "print(f\"Split data into {len(X_train)} training and {len(X_test)} test samples.\")\n",
    "\n",
    "print(\"Running Data-Driven Selection (Lasso)...\")\n",
    "\n",
    "base_lasso_estimator = LogisticRegression(\n",
    "    penalty='l1',\n",
    "    solver='liblinear',\n",
    "    class_weight='balanced',\n",
    "    C=0.1,  \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "ovr_classifier = OneVsRestClassifier(base_lasso_estimator)\n",
    "\n",
    "ovr_classifier.fit(X_train, y_train_ravel)\n",
    "\n",
    "\n",
    "all_coefs = np.vstack([est.coef_ for est in ovr_classifier.estimators_])\n",
    "\n",
    "\n",
    "features_selected_mask = np.sum(np.abs(all_coefs), axis=0) > 1e-5\n",
    "\n",
    "feature_list_A = X_train.columns[features_selected_mask]\n",
    "\n",
    "print(f\"Lasso (C=0.1) selected {len(feature_list_A)} genes.\")\n",
    "print(\"\\n--- Top Genes Selected by Lasso ---\")\n",
    "print(list(feature_list_A[:20])) # Print first 20\n",
    "\n",
    "# --- 5. Plot a Boxplot for the FIRST gene from THIS list ---\n",
    "if len(feature_list_A) > 0:\n",
    "    top_gene_id_lasso = feature_list_A[0]\n",
    "    print(f\"\\nPlotting expression for top Lasso gene: {top_gene_id_lasso}\")\n",
    "\n",
    "    # Create a DataFrame for Plotting (using the full X and y)\n",
    "    plot_df = pd.DataFrame(X[top_gene_id_lasso])\n",
    "    plot_df['label'] = y['label']\n",
    "    text_label_map = {1: 'Healthy', 3: 'GBM'}\n",
    "    plot_df['Diagnosis'] = plot_df['label'].map(text_label_map)\n",
    "\n",
    "    # Create the Boxplot\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.boxplot(\n",
    "        data=plot_df,\n",
    "        x='Diagnosis',\n",
    "        y=top_gene_id_lasso,\n",
    "        palette={'Healthy': '#457B9D', 'GBM': '#E63946'},\n",
    "        order=['Healthy', 'GBM'],\n",
    "        hue='Diagnosis',\n",
    "        legend=False\n",
    "    )\n",
    "    sns.stripplot(\n",
    "        data=plot_df,\n",
    "        x='Diagnosis',\n",
    "        y=top_gene_id_lasso,\n",
    "        color='black',\n",
    "        alpha=0.2,\n",
    "        jitter=0.2,\n",
    "        order=['Healthy', 'GBM']\n",
    "    )\n",
    "    plt.title(f'Expression of Top Lasso Gene: {top_gene_id_lasso}', fontsize=16)\n",
    "    plt.xlabel('Diagnosis', fontsize=12)\n",
    "    plt.ylabel('Scaled Gene Expression', fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Lasso selected 0 genes. Your C value (0.1) might be too strong.\")\n",
    "    print(\"Try increasing C (e.g., C=0.5 or C=1.0) to select more features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4b129d",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ce613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"\\nRunning Data-Driven Selection (RFE)...\")\n",
    "\n",
    "rfe_estimator = LogisticRegression(\n",
    "    solver='lbfgs',  \n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "selector_rfe = RFE(\n",
    "    estimator=rfe_estimator,\n",
    "    n_features_to_select=250,\n",
    "    step=0.1 \n",
    ")\n",
    "\n",
    "print(\"Fitting RFE... (This may take a moment)\")\n",
    "selector_rfe.fit(X_train, y_train_ravel)\n",
    "\n",
    "features_selected_mask_rfe = selector_rfe.get_support()\n",
    "feature_list_B = X_train.columns[features_selected_mask_rfe]\n",
    "\n",
    "print(f\"RFE selected {len(feature_list_B)} genes.\")\n",
    "print(\"\\n--- First 20 Genes Selected by RFE ---\")\n",
    "print(list(feature_list_B[:20]))\n",
    "\n",
    "if len(feature_list_B) > 0:\n",
    "    top_gene_id_rfe = feature_list_B[0]\n",
    "    print(f\"\\nPlotting expression for top RFE gene: {top_gene_id_rfe}\")\n",
    "\n",
    "    plot_df = pd.DataFrame(X[top_gene_id_rfe])\n",
    "    plot_df['label'] = y['label']\n",
    "    text_label_map = {1: 'Healthy', 3: 'GBM'}\n",
    "    plot_df['Diagnosis'] = plot_df['label'].map(text_label_map)\n",
    "\n",
    "    # Create the Boxplot\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.boxplot(\n",
    "        data=plot_df,\n",
    "        x='Diagnosis',\n",
    "        y=top_gene_id_rfe,\n",
    "        palette={'Healthy': '#457B9D', 'GBM': '#E63946'},\n",
    "        order=['Healthy', 'GBM'],\n",
    "        hue='Diagnosis',\n",
    "        legend=False\n",
    "    )\n",
    "    sns.stripplot(\n",
    "        data=plot_df,\n",
    "        x='Diagnosis',\n",
    "        y=top_gene_id_rfe,\n",
    "        color='black',\n",
    "        alpha=0.2,\n",
    "        jitter=0.2,\n",
    "        order=['Healthy', 'GBM']\n",
    "    )\n",
    "    plt.title(f'Expression of Top RFE Gene: {top_gene_id_rfe}', fontsize=16)\n",
    "    plt.xlabel('Diagnosis', fontsize=12)\n",
    "    plt.ylabel('Scaled Gene Expression', fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8327ca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "# We use the gene list from our Lasso (feature_list_A)\n",
    "X_train_lasso = X_train[feature_list_A]\n",
    "X_test_lasso = X_test[feature_list_A]\n",
    "\n",
    "print(f\"--- Training Model 1: Lasso Features ({len(feature_list_A)} genes) ---\")\n",
    "print(f\"Training data shape: {X_train_lasso.shape}\")\n",
    "\n",
    "# We use the same Random Forest model as before\n",
    "rand_forest_lasso = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rand_forest_lasso.fit(X_train_lasso, y_train_ravel)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "y_pred_lasso = rand_forest_lasso.predict(X_test_lasso)\n",
    "\n",
    "print(\"\\n--- Results for Lasso Feature Model ---\")\n",
    "acc_lasso = accuracy_score(y_test, y_pred_lasso)\n",
    "print(f\"Accuracy: {acc_lasso * 100:.2f}%\")\n",
    "\n",
    "target_names = ['Healthy', 'GBM']\n",
    "print(classification_report(y_test, y_pred_lasso, target_names=target_names, zero_division=0))\n",
    "\n",
    "print(\"\\nPlotting Confusion Matrix for Lasso Model:\")\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test,\n",
    "    y_pred_lasso,\n",
    "    display_labels=target_names,\n",
    "    cmap='Blues',\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('Lasso Feature Model Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cc9f28",
   "metadata": {},
   "source": [
    "### LASSO with Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f291c60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "\n",
    "# This assumes X_train, X_test, y_train, y_test, and feature_list_A\n",
    "# (with 2253 genes) are all in memory.\n",
    "X_train_lasso = X_train[feature_list_A]\n",
    "X_test_lasso = X_test[feature_list_A]\n",
    "\n",
    "print(f\"--- Training Model 1: Lasso Features ({len(feature_list_A)} genes) ---\")\n",
    "print(f\"Original training shape: {X_train_lasso.shape}\")\n",
    "print(f\"Original label counts:\\n{y_train['label'].value_counts()}\")\n",
    "\n",
    "# We create an undersampler. It will match the size of all classes\n",
    "# to the size of the *smallest* class (GBM).\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_balanced, y_train_balanced_ravel = rus.fit_resample(X_train_lasso, y_train_ravel)\n",
    "\n",
    "print(\"\\n--- After Undersampling ---\")\n",
    "print(f\"Balanced training shape: {X_train_balanced.shape}\")\n",
    "# This will show a small, but perfectly balanced, set of labels\n",
    "print(f\"Balanced label counts:\\n{pd.Series(y_train_balanced_ravel).value_counts()}\")\n",
    "\n",
    "# We can now *remove* class_weight='balanced' because the data is already balanced.\n",
    "rand_forest_lasso = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# We fit on the NEW balanced data\n",
    "rand_forest_lasso.fit(X_train_balanced, y_train_balanced_ravel)\n",
    "print(\"\\nModel training complete.\")\n",
    "\n",
    "# We still test on the *original, imbalanced* test set\n",
    "y_pred_lasso = rand_forest_lasso.predict(X_test_lasso)\n",
    "\n",
    "print(\"\\n--- Results for Lasso Feature Model (Undersampled) ---\")\n",
    "acc_lasso = accuracy_score(y_test, y_pred_lasso)\n",
    "print(f\"Accuracy: {acc_lasso * 100:.2f}%\")\n",
    "\n",
    "target_names = ['Healthy', 'GBM']\n",
    "print(classification_report(y_test, y_pred_lasso, target_names=target_names))\n",
    "\n",
    "print(\"\\nPlotting Confusion Matrix for Lasso Model:\")\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test,\n",
    "    y_pred_lasso,\n",
    "    display_labels=target_names,\n",
    "    cmap='Blues',\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('Lasso Feature Model Confusion Matrix (Undersampled)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c2a2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "\n",
    "# We use the gene list from our RFE (feature_list_B)\n",
    "X_train_rfe = X_train[feature_list_B]\n",
    "X_test_rfe = X_test[feature_list_B]\n",
    "\n",
    "print(f\"\\n--- Training Model 2: RFE Features ({len(feature_list_B)} genes) ---\")\n",
    "print(f\"Original training shape: {X_train_rfe.shape}\")\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_balanced, y_train_balanced_ravel = rus.fit_resample(X_train_rfe, y_train_ravel)\n",
    "\n",
    "print(\"\\n--- After Undersampling ---\")\n",
    "print(f\"Balanced training shape: {X_train_balanced.shape}\")\n",
    "print(f\"Balanced label counts:\\n{pd.Series(y_train_balanced_ravel).value_counts()}\")\n",
    "\n",
    "rand_forest_rfe = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# We fit on the NEW balanced data\n",
    "rand_forest_rfe.fit(X_train_balanced, y_train_balanced_ravel)\n",
    "print(\"\\nModel training complete.\")\n",
    "\n",
    "y_pred_rfe = rand_forest_rfe.predict(X_test_rfe)\n",
    "\n",
    "print(\"\\n--- Results for RFE Feature Model (Undersampled) ---\")\n",
    "acc_rfe = accuracy_score(y_test, y_pred_rfe)\n",
    "print(f\"Accuracy: {acc_rfe * 100:.2f}%\")\n",
    "\n",
    "target_names = ['Healthy', 'GBM']\n",
    "print(classification_report(y_test, y_pred_rfe, target_names=target_names))\n",
    "\n",
    "print(\"\\nPlotting Confusion Matrix for RFE Model:\")\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test,\n",
    "    y_pred_rfe,\n",
    "    display_labels=target_names,\n",
    "    cmap='Blues',\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('RFE Feature Model Confusion Matrix (Undersampled)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db94402",
   "metadata": {},
   "source": [
    "## Knowledge Driven feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231c6d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "import numpy as np\n",
    "\n",
    "map_filepath = \"data/processed/gene_map.csv\"\n",
    "print(f\"Loading gene map from: {map_filepath}\")\n",
    "\n",
    "try:\n",
    "    map_df = pd.read_csv(map_filepath)\n",
    "    gene_symbol_map = pd.Series(map_df.gene_id_clean.values, index=map_df.gene_name).to_dict()\n",
    "    gene_symbol_map_reverse = {v: k for k, v in gene_symbol_map.items()}\n",
    "    print(\"Gene map loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"FATAL ERROR: '{map_filepath}' not found.\")\n",
    "    print(\"Please run the 'create_gene_map.py' script first.\")\n",
    "    raise\n",
    "\n",
    "knowledge_driven_genes = [\n",
    "    'IDH1', 'EGFR', 'TERT', 'ATRX', 'PTEN', 'MGMT', 'TP53', \n",
    "    'PDGFRA', 'CIC', 'FUBP1', 'CDKN2A', 'PIK3CA'\n",
    "]\n",
    "\n",
    "feature_list_C = []\n",
    "genes_not_found = []\n",
    "\n",
    "for gene_symbol in knowledge_driven_genes:\n",
    "    try:\n",
    "        ensembl_id = gene_symbol_map[gene_symbol]\n",
    "        \n",
    "        if ensembl_id in X_train.columns:\n",
    "            feature_list_C.append(ensembl_id)\n",
    "        else:\n",
    "            genes_not_found.append(f\"{gene_symbol} (ID: {ensembl_id}, not in final data)\")\n",
    "            \n",
    "    except KeyError:\n",
    "        genes_not_found.append(f\"{gene_symbol} (Symbol not in map)\")\n",
    "\n",
    "print(f\"\\n--- Training Model 3: Literature-Driven Features ---\")\n",
    "print(f\"Total genes found: {len(feature_list_C)}\")\n",
    "print(f\"Genes found: {feature_list_C}\")\n",
    "if genes_not_found:\n",
    "    print(f\"Warning: Could not find these genes: {genes_not_found}\")\n",
    "\n",
    "X_train_lit = X_train[feature_list_C]\n",
    "X_test_lit = X_test[feature_list_C]\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_balanced, y_train_balanced_ravel = rus.fit_resample(X_train_lit, y_train_ravel)\n",
    "print(f\"Balanced training shape: {X_train_balanced.shape}\")\n",
    "\n",
    "rand_forest_lit = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rand_forest_lit.fit(X_train_balanced, y_train_balanced_ravel)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "y_pred_lit = rand_forest_lit.predict(X_test_lit)\n",
    "\n",
    "print(\"\\n--- Results for Literature-Driven Model (Undersampled) ---\")\n",
    "acc_lit = accuracy_score(y_test, y_pred_lit)\n",
    "print(f\"Accuracy: {acc_lit * 100:.2f}%\")\n",
    "\n",
    "target_names = ['Healthy', 'GBM']\n",
    "print(classification_report(y_test, y_pred_lit, target_names=target_names))\n",
    "\n",
    "print(\"\\nPlotting Confusion Matrix for Literature-Driven Model:\")\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test,\n",
    "    y_pred_lit,\n",
    "    display_labels=target_names,\n",
    "    cmap='Blues',\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('Literature-Driven Model Confusion Matrix (Undersampled)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e69b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "print(\"\\n--- Training Final Model: Knowledge-Driven + class_weight='balanced' ---\")\n",
    "print(f\"Training on {len(feature_list_C)} expert-selected genes.\")\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Original label counts:\\n{y_train['label'].value_counts()}\")\n",
    "\n",
    "X_train_lit = X_train[feature_list_C]\n",
    "X_test_lit = X_test[feature_list_C]\n",
    "\n",
    "# We use class_weight='balanced' on the *original, imbalanced* data\n",
    "rand_forest_final = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    class_weight='balanced',  # <-- This is the key\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit on the original, imbalanced (but feature-selected) training data\n",
    "rand_forest_final.fit(X_train_lit, y_train_ravel)\n",
    "print(\"\\nModel training complete.\")\n",
    "\n",
    "y_pred_final = rand_forest_final.predict(X_test_lit)\n",
    "\n",
    "print(\"\\n--- Results for Final Model ---\")\n",
    "acc_final = accuracy_score(y_test, y_pred_final)\n",
    "print(f\"Accuracy: {acc_final * 100:.2f}%\")\n",
    "\n",
    "target_names = ['Healthy', 'GBM']\n",
    "print(classification_report(y_test, y_pred_final, target_names=target_names))\n",
    "\n",
    "# --- 4. Plot Confusion Matrix ---\n",
    "print(\"\\nPlotting Confusion Matrix for Final Model:\")\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test,\n",
    "    y_pred_final,\n",
    "    display_labels=target_names,\n",
    "    cmap='Blues',\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('Final Model (Knowledge-Driven + Balanced Weights)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e83bb88",
   "metadata": {},
   "source": [
    "## Advanced Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdee1b5",
   "metadata": {},
   "source": [
    "### SHAP Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7104ef95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "\n",
    "print(\"Generating SHAP values for knowledge-driven model\")\n",
    "\n",
    "explainer = shap.TreeExplainer(rand_forest_lit)\n",
    "shap_values_raw = explainer.shap_values(X_test_lit)\n",
    "\n",
    "print(f\"Raw SHAP values type: {type(shap_values_raw)}\")\n",
    "if isinstance(shap_values_raw, list):\n",
    "    print(f\"List length: {len(shap_values_raw)}\")\n",
    "    for i, sv in enumerate(shap_values_raw):\n",
    "        print(f\"  Class {i} shape: {sv.shape}\")\n",
    "    shap_values_class = shap_values_raw[1]\n",
    "elif isinstance(shap_values_raw, np.ndarray):\n",
    "    print(f\"Array shape: {shap_values_raw.shape}\")\n",
    "    if len(shap_values_raw.shape) == 3:\n",
    "        shap_values_class = shap_values_raw[:, :, 1]\n",
    "    else:\n",
    "        shap_values_class = shap_values_raw\n",
    "else:\n",
    "    shap_values_class = shap_values_raw\n",
    "\n",
    "print(f\"Final SHAP values shape: {shap_values_class.shape}\")\n",
    "print(f\"Expected value: {explainer.expected_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521722fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_names_display = [gene_symbol_map_reverse.get(col, col) for col in X_test_lit.columns]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(shap_values_class, X_test_lit, feature_names=gene_names_display, show=False)\n",
    "plt.title(\"SHAP Feature Importance for 12 Knowledge-Driven Genes\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81862f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified_indices = np.where(y_pred_lit != y_test.values.ravel())[0]\n",
    "\n",
    "if len(misclassified_indices) > 0:\n",
    "    sample_idx = misclassified_indices[0]\n",
    "    \n",
    "    true_label = y_test.values.ravel()[sample_idx]\n",
    "    pred_label = y_pred_lit[sample_idx]\n",
    "    \n",
    "    print(f\"\\nMisclassified sample analysis:\")\n",
    "    print(f\"True label: {true_label}, Predicted: {pred_label}\")\n",
    "    \n",
    "    base_val = explainer.expected_value[1] if isinstance(explainer.expected_value, (list, np.ndarray)) else explainer.expected_value\n",
    "    \n",
    "    shap.waterfall_plot(\n",
    "        shap.Explanation(\n",
    "            values=shap_values_class[sample_idx],\n",
    "            base_values=base_val,\n",
    "            data=X_test_lit.iloc[sample_idx].values,\n",
    "            feature_names=gene_names_display\n",
    "        ),\n",
    "        show=False\n",
    "    )\n",
    "    plt.title(f\"SHAP Explanation for Misclassified Sample\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No misclassified samples found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e089b5",
   "metadata": {},
   "source": [
    "### Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29924363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "print(\"Computing learning curves for knowledge-driven model\")\n",
    "print(\"NOTE: Learning curve uses ORIGINAL training data with undersampling in pipeline\")\n",
    "print(f\"Original training set: {X_train[feature_list_C].shape[0]} samples\")\n",
    "print(f\"Class distribution: {pd.Series(y_train_ravel).value_counts().to_dict()}\\n\")\n",
    "\n",
    "# Create pipeline with undersampling + model\n",
    "# This ensures undersampling is applied at each training size\n",
    "pipeline = ImbPipeline([\n",
    "    ('sampler', RandomUnderSampler(random_state=42)),\n",
    "    ('model', RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Use ORIGINAL training data (X_train, y_train_ravel)\n",
    "# Learning curve will apply undersampling internally for each fold\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    pipeline,\n",
    "    X_train[feature_list_C],  # Use original training data with selected features\n",
    "    y_train_ravel,            # Use original training labels\n",
    "    cv=5,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "val_mean = np.mean(val_scores, axis=1)\n",
    "val_std = np.std(val_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_mean, label='Training score', color='blue', marker='o')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.15, color='blue')\n",
    "plt.plot(train_sizes, val_mean, label='Cross-validation score', color='red', marker='s')\n",
    "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.15, color='red')\n",
    "plt.xlabel('Training Set Size (from original 1043 samples)')\n",
    "plt.ylabel('F1 Score (Macro)')\n",
    "plt.title('Learning Curve - Knowledge-Driven Model (12 genes)\\nWith Undersampling Pipeline')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final training score: {train_mean[-1]:.3f}\")\n",
    "print(f\"Final validation score: {val_mean[-1]:.3f}\")\n",
    "print(f\"Gap: {train_mean[-1] - val_mean[-1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0d9c38",
   "metadata": {},
   "source": [
    "### Calibration Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b24cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "print(\"Computing calibration curves for all three models\\n\")\n",
    "\n",
    "# Get predicted probabilities for GBM class (class index 1 in binary after conversion)\n",
    "y_test_binary = (y_test.values.ravel() == 3).astype(int)\n",
    "\n",
    "# LASSO model probabilities\n",
    "y_proba_lasso = rand_forest_lasso.predict_proba(X_test[feature_list_A])[:, 1]\n",
    "prob_true_lasso, prob_pred_lasso = calibration_curve(\n",
    "    y_test_binary, y_proba_lasso, n_bins=10, strategy='uniform'\n",
    ")\n",
    "\n",
    "# RFE model probabilities\n",
    "y_proba_rfe = rand_forest_rfe.predict_proba(X_test[feature_list_B])[:, 1]\n",
    "prob_true_rfe, prob_pred_rfe = calibration_curve(\n",
    "    y_test_binary, y_proba_rfe, n_bins=10, strategy='uniform'\n",
    ")\n",
    "\n",
    "# Knowledge-driven model probabilities\n",
    "y_proba_lit = rand_forest_lit.predict_proba(X_test[feature_list_C])[:, 1]\n",
    "prob_true_lit, prob_pred_lit = calibration_curve(\n",
    "    y_test_binary, y_proba_lit, n_bins=10, strategy='uniform'\n",
    ")\n",
    "\n",
    "# Plot all three calibration curves\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Perfectly calibrated')\n",
    "plt.plot(prob_pred_lasso, prob_true_lasso, marker='o', linewidth=2, \n",
    "         label='LASSO (460 genes)', markersize=8)\n",
    "plt.plot(prob_pred_rfe, prob_true_rfe, marker='s', linewidth=2,\n",
    "         label='RFE (250 genes)', markersize=8)\n",
    "plt.plot(prob_pred_lit, prob_true_lit, marker='^', linewidth=2,\n",
    "         label='Knowledge (12 genes)', markersize=8)\n",
    "\n",
    "plt.xlabel('Mean Predicted Probability', fontsize=12)\n",
    "plt.ylabel('Fraction of Positives (True GBM Rate)', fontsize=12)\n",
    "plt.title('Calibration Curves - GBM Detection\\nAll Models with Undersampling', fontsize=14)\n",
    "plt.legend(loc='upper left', fontsize=10)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1701cb1",
   "metadata": {},
   "source": [
    "### ROC Curves and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb8acbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "print(\"Computing ROC curves for all three models\")\n",
    "print(\"NOTE: All models trained with undersampling, tested on imbalanced data\\n\")\n",
    "\n",
    "y_test_binary = (y_test.values.ravel() == 3).astype(int)\n",
    "\n",
    "# Get predicted probabilities (consistent feature selection)\n",
    "y_proba_lasso = rand_forest_lasso.predict_proba(X_test[feature_list_A])[:, 1]\n",
    "y_proba_rfe = rand_forest_rfe.predict_proba(X_test[feature_list_B])[:, 1]\n",
    "y_proba_lit = rand_forest_lit.predict_proba(X_test[feature_list_C])[:, 1]\n",
    "\n",
    "# Calculate ROC curves\n",
    "fpr_lasso, tpr_lasso, _ = roc_curve(y_test_binary, y_proba_lasso)\n",
    "fpr_rfe, tpr_rfe, _ = roc_curve(y_test_binary, y_proba_rfe)\n",
    "fpr_lit, tpr_lit, _ = roc_curve(y_test_binary, y_proba_lit)\n",
    "\n",
    "# Calculate AUC scores\n",
    "auc_lasso = auc(fpr_lasso, tpr_lasso)\n",
    "auc_rfe = auc(fpr_rfe, tpr_rfe)\n",
    "auc_lit = auc(fpr_lit, tpr_lit)\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr_lasso, tpr_lasso, label=f'LASSO ({len(feature_list_A)} genes) AUC={auc_lasso:.3f}', linewidth=2.5)\n",
    "plt.plot(fpr_rfe, tpr_rfe, label=f'RFE ({len(feature_list_B)} genes) AUC={auc_rfe:.3f}', linewidth=2.5)\n",
    "plt.plot(fpr_lit, tpr_lit, label=f'Knowledge ({len(feature_list_C)} genes) AUC={auc_lit:.3f}', linewidth=2.5)\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random classifier (AUC=0.50)', linewidth=1.5, alpha=0.7)\n",
    "\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)', fontsize=12)\n",
    "plt.ylabel('True Positive Rate (Sensitivity/Recall)', fontsize=12)\n",
    "plt.title('ROC Curves - GBM Detection\\nAll Models with Undersampling', fontsize=14)\n",
    "plt.legend(loc='lower right', fontsize=10)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.xlim([-0.02, 1.02])\n",
    "plt.ylim([-0.02, 1.02])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ba005b",
   "metadata": {},
   "source": [
    "### Precision-Recall Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59524aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "print(\"Computing Precision-Recall curves for all three models\")\n",
    "print(\"NOTE: PR curves are more informative than ROC for imbalanced datasets\\n\")\n",
    "\n",
    "# Calculate PR curves (y_test_binary and probabilities already defined above)\n",
    "precision_lasso, recall_lasso, _ = precision_recall_curve(y_test_binary, y_proba_lasso)\n",
    "precision_rfe, recall_rfe, _ = precision_recall_curve(y_test_binary, y_proba_rfe)\n",
    "precision_lit, recall_lit, _ = precision_recall_curve(y_test_binary, y_proba_lit)\n",
    "\n",
    "# Calculate Average Precision scores\n",
    "ap_lasso = average_precision_score(y_test_binary, y_proba_lasso)\n",
    "ap_rfe = average_precision_score(y_test_binary, y_proba_rfe)\n",
    "ap_lit = average_precision_score(y_test_binary, y_proba_lit)\n",
    "\n",
    "# Baseline = class prevalence in test set\n",
    "baseline = y_test_binary.sum() / len(y_test_binary)\n",
    "num_gbm = y_test_binary.sum()\n",
    "num_healthy = len(y_test_binary) - num_gbm\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(recall_lasso, precision_lasso, label=f'LASSO ({len(feature_list_A)} genes) AP={ap_lasso:.3f}', linewidth=2.5)\n",
    "plt.plot(recall_rfe, precision_rfe, label=f'RFE ({len(feature_list_B)} genes) AP={ap_rfe:.3f}', linewidth=2.5)\n",
    "plt.plot(recall_lit, precision_lit, label=f'Knowledge ({len(feature_list_C)} genes) AP={ap_lit:.3f}', linewidth=2.5)\n",
    "plt.axhline(y=baseline, color='k', linestyle='--', \n",
    "            label=f'No-skill baseline (AP={baseline:.3f})\\n{num_gbm} GBM / {num_healthy} Healthy', \n",
    "            linewidth=1.5, alpha=0.7)\n",
    "\n",
    "plt.xlabel('Recall (Sensitivity)', fontsize=12)\n",
    "plt.ylabel('Precision (Positive Predictive Value)', fontsize=12)\n",
    "plt.title('Precision-Recall Curves - GBM Detection\\nAll Models with Undersampling', fontsize=14)\n",
    "plt.legend(loc='upper right', fontsize=10)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.xlim([-0.02, 1.02])\n",
    "plt.ylim([-0.02, 1.02])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f57389",
   "metadata": {},
   "source": [
    "### Stratified K-Fold Validation\n",
    "We evaluate each feature subset with 5-fold Stratified CV using an undersampled RandomForest pipeline to quantify variance in macro F1 and GBM recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2194a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import make_scorer, f1_score, recall_score\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Custom scorer to avoid pos_label issue with macro F1\n",
    "def macro_f1_scorer(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "\n",
    "def gbm_recall_scorer(y_true, y_pred):\n",
    "    return recall_score(y_true, y_pred, pos_label=3, zero_division=0)\n",
    "\n",
    "feature_sets = [\n",
    "    (\"LASSO (323 genes)\", feature_list_A),\n",
    "    (\"RFE (250 genes)\", feature_list_B),\n",
    "    (\"Knowledge (12 genes)\", feature_list_C)\n",
    "]\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_rows = []\n",
    "\n",
    "for name, feature_list in feature_sets:\n",
    "    X_subset = X[feature_list]\n",
    "    pipeline = Pipeline([\n",
    "        ('sampler', RandomUnderSampler(random_state=42)),\n",
    "        ('model', RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "    scores = cross_validate(\n",
    "        pipeline,\n",
    "        X_subset,\n",
    "        y.values.ravel(),\n",
    "        cv=cv,\n",
    "        scoring={\n",
    "            'macro_f1': make_scorer(macro_f1_scorer),\n",
    "            'gbm_recall': make_scorer(gbm_recall_scorer)\n",
    "        },\n",
    "        n_jobs=-1,\n",
    "        return_train_score=False\n",
    "    )\n",
    "    cv_rows.append({\n",
    "        'Feature Set': name,\n",
    "        'Macro F1 (mean)': float(np.mean(scores['test_macro_f1'])),\n",
    "        'Macro F1 (std)': float(np.std(scores['test_macro_f1'])),\n",
    "        'GBM Recall (mean)': float(np.mean(scores['test_gbm_recall'])),\n",
    "        'GBM Recall (std)': float(np.std(scores['test_gbm_recall']))\n",
    "    })\n",
    "\n",
    "cv_results_df = pd.DataFrame(cv_rows)\n",
    "display(cv_results_df.round(3))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "x = np.arange(len(cv_results_df))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, cv_results_df['Macro F1 (mean)'], width, \n",
    "        label='Macro F1', color='#457B9D', yerr=cv_results_df['Macro F1 (std)'], capsize=5)\n",
    "plt.bar(x + width/2, cv_results_df['GBM Recall (mean)'], width,\n",
    "        label='GBM Recall', color='#E63946', yerr=cv_results_df['GBM Recall (std)'], capsize=5)\n",
    "\n",
    "plt.ylabel('Score')\n",
    "plt.title('Stratified 5-Fold Cross-Validation Results')\n",
    "plt.xticks(x, cv_results_df['Feature Set'], rotation=20, ha='right')\n",
    "plt.legend()\n",
    "plt.ylim(0, 1.0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
