# Configuration for GBM Classification Pipeline
# Hogeschool Rotterdam - Minor AI in Healthcare
# Retake Project

# General settings
random_state: 42
project_name: "GBM_Classification"
verbose: true

# Cross-validation configuration
cv:
  outer_folds: 5  # Academisch standaard voor robuuste performance schatting
  inner_folds: 3  # Voldoende voor hyperparameter tuning zonder overmatige compute
  stratified: true  # Behoud class distributie in folds
  shuffle: true
  test_size: 0.2  # 20% hold-out test set voor finale evaluatie

# Preprocessing settings
preprocessing:
  batch_correction: "combat"  # Options: combat, harmony, none
  scaler: "standard"  # Options: standard, robust, minmax
  remove_low_variance: true
  variance_threshold: 0.01
  correlation_threshold: 0.95

# Feature selection routes
features:
  routes:
    - "filter_l1"  # Variance + correlation + L1: behoudt interpreteerbare genes
    - "pca"        # Dimensionality reduction: maximaliseert variance
  k_best: 200  # Balans tussen performance en compute tijd (~2-3 uur)
  pca_components: 200  # Meer components voor hogere variance (targeting 80-90%)
  stability_selection:
    enabled: false  # Uitgeschakeld voor compute efficiency
    n_bootstrap: 100
    threshold: 0.7
  bio_panel_path: "metadata/biopanel.csv"

# Model configurations
models:
  lr_elasticnet:
    enabled: true
    param_grid:
      classifier__C: [0.001, 0.01, 0.1, 1.0, 10.0]  # Wide range voor regularization strength
      classifier__l1_ratio: [0.3, 0.5, 0.7]  # Mix L1/L2 penalties
      classifier__max_iter: [2000]  # Verhoogd voor convergence
  
  random_forest:
    enabled: true
    param_grid:
      classifier__n_estimators: [100, 200, 300]  # Meer trees = stabieler
      classifier__max_depth: [10, 20, 30, null]  # Verschillende dieptes
      classifier__min_samples_split: [2, 5, 10]  # Regularization parameter
      classifier__min_samples_leaf: [1, 2, 4]  # Leaf size regularization
      classifier__class_weight: ["balanced", "balanced_subsample"]  # Handle imbalance
  
  lightgbm:
    enabled: true
    param_grid:
      classifier__n_estimators: [100, 200, 300]  # Boosting rounds
      classifier__learning_rate: [0.01, 0.05, 0.1]  # Learning rate trade-off
      classifier__max_depth: [5, 10, 15]  # Tree complexity
      classifier__num_leaves: [31, 50, 100]  # Leaf nodes
      classifier__min_child_samples: [10, 20, 30]  # Minimum samples per leaf
      classifier__class_weight: ["balanced"]  # Handle class imbalance

# Evaluation settings
evaluation:
  metrics:
    - "accuracy"
    - "precision"
    - "recall"
    - "f1"
    - "roc_auc"
    - "pr_auc"
  calibration:
    enabled: true
    n_bins: 10
  decision_curve:
    enabled: true
    threshold_range: [0.0, 1.0]
    n_thresholds: 100
  bootstrap_ci:
    enabled: true
    n_bootstrap: 1000
    confidence: 0.95

# SHAP settings
shap:
  enabled: true
  n_samples: 100  # For background dataset
  plots:
    - "beeswarm"
    - "bar"
    - "waterfall"
    - "dependence"
  top_features: 20

# Ablation study settings
ablation:
  enabled: true
  tests:
    - name: "no_batch_correction"
      batch_correction: null
    - name: "pca_only"
      features: ["pca"]
    - name: "stability_panel_only"
      features: ["filter_l1"]

# Paths
paths:
  raw: "data/raw"
  interim: "data/interim"
  processed: "data/processed"
  metadata: "metadata"
  figures: "figures"
  reports: "reports"
  notebooks: "notebooks"
  src: "src"
  scripts: "scripts"

# Output settings
output:
  save_models: true
  save_predictions: true
  save_probabilities: true
  figure_format: "png"
  figure_dpi: 300
  table_format: "csv"
